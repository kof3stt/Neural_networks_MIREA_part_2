{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2418138b",
   "metadata": {},
   "source": [
    "# Генеративно-состязательная сеть"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3e1a95",
   "metadata": {},
   "source": [
    "## Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3e6b42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from typing import Optional, Callable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea1b96d",
   "metadata": {},
   "source": [
    "## Настройка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c554696",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "os.makedirs('gan_textures', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0336da2c",
   "metadata": {},
   "source": [
    "## Определение класса TexturesDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ea3c7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TexturesDataset(Dataset):\n",
    "    \"\"\"Кастомный датасет для загрузки текстурных изображений из папки.\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir: str, transform: Optional[Callable] = None) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (str): Путь к директории с изображениями.\n",
    "            transform (Callable, optional): Трансформации, применяемые к изображениям.\n",
    "        \"\"\"\n",
    "        self.paths = sorted([\n",
    "            os.path.join(root_dir, f)\n",
    "            for f in os.listdir(root_dir)\n",
    "            if f.lower().endswith(('.png', '.jpg', 'jpeg', 'bmp'))\n",
    "        ])\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Возвращает количество изображений в датасете.\"\"\"\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> torch.Tensor:\n",
    "        \"\"\"Загружает и возвращает одно изображение по индексу.\"\"\"\n",
    "        img = Image.open(self.paths[idx]).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ceeda4",
   "metadata": {},
   "source": [
    "## Подготовка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0de458fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((1024,1024)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,)*3, (0.5,)*3),\n",
    "])\n",
    "\n",
    "dataset = TexturesDataset('textures', transform)\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True,\n",
    "                        num_workers=0, pin_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ff3908",
   "metadata": {},
   "source": [
    "## Инициализация весов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd415cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "        nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        if m.weight is not None:\n",
    "            nn.init.normal_(m.weight, 1.0, 0.02)\n",
    "            nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, nn.ConvTranspose2d):\n",
    "        if m.weight is not None:\n",
    "            nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37950653",
   "metadata": {},
   "source": [
    "## Генератор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33cfbebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\"Генератор изображений для GAN.\"\"\"\n",
    "\n",
    "    def __init__(self, latent_dim: int = 128) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            latent_dim (int): Размерность латентного вектора.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.fc = nn.Linear(latent_dim, 512*4*4)\n",
    "\n",
    "        def up(in_c: int, out_c: int) -> nn.Sequential:\n",
    "            \"\"\"Строит блок апсемплинга.\"\"\"\n",
    "            return nn.Sequential(\n",
    "                nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
    "                nn.Conv2d(in_c, out_c, 1),\n",
    "                nn.InstanceNorm2d(out_c),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(out_c, out_c, 3, padding=1),\n",
    "                nn.InstanceNorm2d(out_c),\n",
    "                nn.ReLU(True),\n",
    "            )\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            self.fc,\n",
    "            nn.ReLU(True),\n",
    "            nn.Unflatten(1, (512, 4, 4)),\n",
    "            up(512, 512),  # 4 → 8\n",
    "            up(512, 256),  # 8 → 16\n",
    "            up(256, 256),  # 16 → 32\n",
    "            up(256, 128),  # 32 → 64\n",
    "            up(128,  64),  # 64 → 128\n",
    "            up(64,   32),  # 128 → 256\n",
    "            up(32,   16),  # 256 → 512\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),  # 512 → 1024\n",
    "            nn.Conv2d(16, 3, 3, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Прямой проход генератора.\"\"\"\n",
    "        return self.net(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122595a0",
   "metadata": {},
   "source": [
    "## Дискриминатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7221bbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \"\"\"Дискриминатор для оценки реальности изображений.\"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        def block(in_c: int, out_c: int) -> nn.Sequential:\n",
    "            \"\"\"Строит сверточный блок.\"\"\"\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_c, out_c, 4, 2, 1),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                nn.Dropout(0.25)\n",
    "            )\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            block(3,   64),  # 1024 → 512\n",
    "            block(64, 128),  # 512 → 256\n",
    "            block(128, 256), # 256 → 128\n",
    "            block(256, 512), # 128 → 64\n",
    "        )\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Прямой проход дискриминатора.\"\"\"\n",
    "        x = self.features(x)\n",
    "        x = self.pool(x)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb56052",
   "metadata": {},
   "source": [
    "## Инициализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99cf2d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 128\n",
    "epochs = 2\n",
    "G = Generator(latent_dim).to(device)\n",
    "D = Discriminator().to(device)\n",
    "G.apply(weights_init)\n",
    "D.apply(weights_init)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "opt_G = optim.Adam(G.parameters(), lr=2e-4, betas=(0.5,0.999))\n",
    "opt_D = optim.Adam(D.parameters(), lr=1e-4, betas=(0.5,0.999))\n",
    "\n",
    "g_losses, d_losses = [], []\n",
    "real_probs, fake_probs = [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f88300",
   "metadata": {},
   "source": [
    "## Цикл обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e78d434a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[001/2] [001/086] D_loss:0.6918 G_loss:0.6910 R:0.50 F:0.50\n",
      "[001/2] [002/086] D_loss:0.6847 G_loss:0.6882 R:0.51 F:0.50\n",
      "[001/2] [003/086] D_loss:0.6767 G_loss:0.6826 R:0.52 F:0.50\n",
      "[001/2] [004/086] D_loss:0.6674 G_loss:0.6720 R:0.54 F:0.51\n",
      "[001/2] [005/086] D_loss:0.6509 G_loss:0.6533 R:0.57 F:0.52\n",
      "[001/2] [006/086] D_loss:0.6387 G_loss:0.6216 R:0.61 F:0.53\n",
      "[001/2] [007/086] D_loss:0.6256 G_loss:0.5736 R:0.68 F:0.55\n",
      "[001/2] [008/086] D_loss:0.6425 G_loss:0.5398 R:0.72 F:0.59\n",
      "[001/2] [009/086] D_loss:0.7051 G_loss:0.5485 R:0.67 F:0.62\n",
      "[001/2] [010/086] D_loss:0.6632 G_loss:0.5675 R:0.71 F:0.61\n",
      "[001/2] [011/086] D_loss:0.6574 G_loss:0.5810 R:0.69 F:0.59\n",
      "[001/2] [012/086] D_loss:0.6827 G_loss:0.5937 R:0.62 F:0.58\n",
      "[001/2] [013/086] D_loss:0.6774 G_loss:0.6033 R:0.61 F:0.57\n",
      "[001/2] [014/086] D_loss:0.6838 G_loss:0.6135 R:0.59 F:0.56\n",
      "[001/2] [015/086] D_loss:0.6716 G_loss:0.6180 R:0.60 F:0.55\n",
      "[001/2] [016/086] D_loss:0.6910 G_loss:0.6309 R:0.56 F:0.55\n",
      "[001/2] [017/086] D_loss:0.6797 G_loss:0.6347 R:0.57 F:0.54\n",
      "[001/2] [018/086] D_loss:0.6816 G_loss:0.6378 R:0.56 F:0.54\n",
      "[001/2] [019/086] D_loss:0.6821 G_loss:0.6339 R:0.56 F:0.54\n",
      "[001/2] [020/086] D_loss:0.6775 G_loss:0.6311 R:0.57 F:0.54\n",
      "[001/2] [021/086] D_loss:0.6692 G_loss:0.6365 R:0.58 F:0.54\n",
      "[001/2] [022/086] D_loss:0.6752 G_loss:0.6462 R:0.57 F:0.54\n",
      "[001/2] [023/086] D_loss:0.6417 G_loss:0.6534 R:0.62 F:0.53\n",
      "[001/2] [024/086] D_loss:0.6489 G_loss:0.6530 R:0.60 F:0.53\n",
      "[001/2] [025/086] D_loss:0.6609 G_loss:0.6294 R:0.58 F:0.53\n",
      "[001/2] [026/086] D_loss:0.6389 G_loss:0.6620 R:0.65 F:0.55\n",
      "[001/2] [027/086] D_loss:0.6478 G_loss:0.6839 R:0.61 F:0.53\n",
      "[001/2] [028/086] D_loss:0.6215 G_loss:0.6766 R:0.63 F:0.51\n",
      "[001/2] [029/086] D_loss:0.6750 G_loss:0.6648 R:0.55 F:0.52\n",
      "[001/2] [030/086] D_loss:0.6217 G_loss:0.6547 R:0.67 F:0.53\n",
      "[001/2] [031/086] D_loss:0.6672 G_loss:0.6565 R:0.67 F:0.54\n",
      "[001/2] [032/086] D_loss:0.6913 G_loss:0.6491 R:0.62 F:0.54\n",
      "[001/2] [033/086] D_loss:0.6426 G_loss:0.6364 R:0.63 F:0.54\n",
      "[001/2] [034/086] D_loss:0.7166 G_loss:0.6309 R:0.53 F:0.55\n",
      "[001/2] [035/086] D_loss:0.6226 G_loss:0.6347 R:0.72 F:0.55\n",
      "[001/2] [036/086] D_loss:0.6454 G_loss:0.6278 R:0.64 F:0.54\n",
      "[001/2] [037/086] D_loss:0.6500 G_loss:0.6139 R:0.63 F:0.55\n",
      "[001/2] [038/086] D_loss:0.6717 G_loss:0.5850 R:0.61 F:0.56\n",
      "[001/2] [039/086] D_loss:0.6730 G_loss:0.5697 R:0.64 F:0.58\n",
      "[001/2] [040/086] D_loss:0.6727 G_loss:0.5853 R:0.66 F:0.59\n",
      "[001/2] [041/086] D_loss:0.6747 G_loss:0.6046 R:0.64 F:0.58\n",
      "[001/2] [042/086] D_loss:0.6711 G_loss:0.5977 R:0.61 F:0.56\n",
      "[001/2] [043/086] D_loss:0.6611 G_loss:0.6083 R:0.64 F:0.57\n",
      "[001/2] [044/086] D_loss:0.6824 G_loss:0.6000 R:0.59 F:0.56\n",
      "[001/2] [045/086] D_loss:0.6872 G_loss:0.5953 R:0.60 F:0.57\n",
      "[001/2] [046/086] D_loss:0.6951 G_loss:0.6174 R:0.59 F:0.57\n",
      "[001/2] [047/086] D_loss:0.6961 G_loss:0.6400 R:0.56 F:0.56\n",
      "[001/2] [048/086] D_loss:0.6900 G_loss:0.6373 R:0.55 F:0.54\n",
      "[001/2] [049/086] D_loss:0.6874 G_loss:0.6100 R:0.55 F:0.54\n",
      "[001/2] [050/086] D_loss:0.6889 G_loss:0.6255 R:0.58 F:0.56\n",
      "[001/2] [051/086] D_loss:0.6798 G_loss:0.6557 R:0.57 F:0.55\n",
      "[001/2] [052/086] D_loss:0.6687 G_loss:0.6698 R:0.56 F:0.53\n",
      "[001/2] [053/086] D_loss:0.6810 G_loss:0.7167 R:0.53 F:0.52\n",
      "[001/2] [054/086] D_loss:0.6714 G_loss:0.6728 R:0.51 F:0.49\n",
      "[001/2] [055/086] D_loss:0.6645 G_loss:0.6906 R:0.56 F:0.52\n",
      "[001/2] [056/086] D_loss:0.6799 G_loss:0.7208 R:0.53 F:0.51\n",
      "[001/2] [057/086] D_loss:0.6810 G_loss:0.6966 R:0.50 F:0.49\n",
      "[001/2] [058/086] D_loss:0.6873 G_loss:0.6129 R:0.51 F:0.50\n",
      "[001/2] [059/086] D_loss:0.6858 G_loss:0.6948 R:0.58 F:0.56\n",
      "[001/2] [060/086] D_loss:0.6702 G_loss:0.7525 R:0.54 F:0.50\n",
      "[001/2] [061/086] D_loss:0.6864 G_loss:0.7076 R:0.48 F:0.47\n",
      "[001/2] [062/086] D_loss:0.6434 G_loss:0.6914 R:0.56 F:0.49\n",
      "[001/2] [063/086] D_loss:0.6274 G_loss:0.7448 R:0.61 F:0.50\n",
      "[001/2] [064/086] D_loss:0.6187 G_loss:0.7378 R:0.59 F:0.47\n",
      "[001/2] [065/086] D_loss:0.6349 G_loss:0.6833 R:0.57 F:0.48\n",
      "[001/2] [066/086] D_loss:0.6740 G_loss:0.6336 R:0.61 F:0.55\n",
      "[001/2] [067/086] D_loss:0.7125 G_loss:0.6821 R:0.57 F:0.57\n",
      "[001/2] [068/086] D_loss:0.7394 G_loss:0.6438 R:0.52 F:0.54\n",
      "[001/2] [069/086] D_loss:0.7073 G_loss:0.5694 R:0.53 F:0.54\n",
      "[001/2] [070/086] D_loss:0.6728 G_loss:0.6086 R:0.69 F:0.61\n",
      "[001/2] [071/086] D_loss:0.6484 G_loss:0.6635 R:0.66 F:0.57\n",
      "[001/2] [072/086] D_loss:0.6819 G_loss:0.7206 R:0.54 F:0.52\n",
      "[001/2] [073/086] D_loss:0.6722 G_loss:0.7270 R:0.52 F:0.49\n",
      "[001/2] [074/086] D_loss:0.6625 G_loss:0.6962 R:0.52 F:0.48\n",
      "[001/2] [075/086] D_loss:0.6660 G_loss:0.6766 R:0.55 F:0.51\n",
      "[001/2] [076/086] D_loss:0.6883 G_loss:0.6425 R:0.53 F:0.53\n",
      "[001/2] [077/086] D_loss:0.6979 G_loss:0.6724 R:0.55 F:0.55\n",
      "[001/2] [078/086] D_loss:0.7267 G_loss:0.6664 R:0.48 F:0.52\n",
      "[001/2] [079/086] D_loss:0.7033 G_loss:0.6466 R:0.51 F:0.52\n",
      "[001/2] [080/086] D_loss:0.6893 G_loss:0.6335 R:0.54 F:0.53\n",
      "[001/2] [081/086] D_loss:0.6714 G_loss:0.6780 R:0.58 F:0.54\n",
      "[001/2] [082/086] D_loss:0.6542 G_loss:0.7612 R:0.57 F:0.51\n",
      "[001/2] [083/086] D_loss:0.6655 G_loss:0.7624 R:0.50 F:0.46\n",
      "[001/2] [084/086] D_loss:0.6583 G_loss:0.7361 R:0.51 F:0.46\n",
      "[001/2] [085/086] D_loss:0.6743 G_loss:0.6353 R:0.51 F:0.48\n",
      "[001/2] [086/086] D_loss:0.6763 G_loss:0.7844 R:0.59 F:0.55\n",
      "[002/2] [001/086] D_loss:0.5517 G_loss:0.8491 R:0.71 F:0.45\n",
      "[002/2] [002/086] D_loss:0.6457 G_loss:0.8025 R:0.51 F:0.42\n",
      "[002/2] [003/086] D_loss:0.6670 G_loss:0.7013 R:0.51 F:0.44\n",
      "[002/2] [004/086] D_loss:0.7029 G_loss:0.6458 R:0.55 F:0.51\n",
      "[002/2] [005/086] D_loss:0.7388 G_loss:0.6523 R:0.51 F:0.54\n",
      "[002/2] [006/086] D_loss:0.7073 G_loss:0.6559 R:0.53 F:0.53\n",
      "[002/2] [007/086] D_loss:0.7166 G_loss:0.6676 R:0.52 F:0.54\n",
      "[002/2] [008/086] D_loss:0.6865 G_loss:0.6966 R:0.55 F:0.53\n",
      "[002/2] [009/086] D_loss:0.6708 G_loss:0.7238 R:0.54 F:0.51\n",
      "[002/2] [010/086] D_loss:0.6476 G_loss:0.6799 R:0.55 F:0.49\n",
      "[002/2] [011/086] D_loss:0.6339 G_loss:0.6447 R:0.61 F:0.52\n",
      "[002/2] [012/086] D_loss:0.6644 G_loss:0.6242 R:0.60 F:0.55\n",
      "[002/2] [013/086] D_loss:0.6856 G_loss:0.6463 R:0.58 F:0.56\n",
      "[002/2] [014/086] D_loss:0.6614 G_loss:0.6738 R:0.59 F:0.54\n",
      "[002/2] [015/086] D_loss:0.6761 G_loss:0.6645 R:0.54 F:0.52\n",
      "[002/2] [016/086] D_loss:0.6800 G_loss:0.6982 R:0.55 F:0.53\n",
      "[002/2] [017/086] D_loss:0.6750 G_loss:0.7155 R:0.54 F:0.50\n",
      "[002/2] [018/086] D_loss:0.6810 G_loss:0.7106 R:0.52 F:0.50\n",
      "[002/2] [019/086] D_loss:0.6671 G_loss:0.6395 R:0.53 F:0.49\n",
      "[002/2] [020/086] D_loss:0.7077 G_loss:0.7730 R:0.53 F:0.54\n",
      "[002/2] [021/086] D_loss:0.6770 G_loss:0.7208 R:0.48 F:0.45\n",
      "[002/2] [022/086] D_loss:0.6630 G_loss:0.6530 R:0.53 F:0.49\n",
      "[002/2] [023/086] D_loss:0.6302 G_loss:0.8226 R:0.63 F:0.53\n",
      "[002/2] [024/086] D_loss:0.6663 G_loss:0.8086 R:0.48 F:0.43\n",
      "[002/2] [025/086] D_loss:0.6670 G_loss:0.7686 R:0.49 F:0.44\n",
      "[002/2] [026/086] D_loss:0.6901 G_loss:0.6710 R:0.47 F:0.46\n",
      "[002/2] [027/086] D_loss:0.6366 G_loss:0.6693 R:0.63 F:0.52\n",
      "[002/2] [028/086] D_loss:0.6412 G_loss:0.7779 R:0.64 F:0.52\n",
      "[002/2] [029/086] D_loss:0.6826 G_loss:0.7678 R:0.48 F:0.46\n",
      "[002/2] [030/086] D_loss:0.6856 G_loss:0.7654 R:0.48 F:0.46\n",
      "[002/2] [031/086] D_loss:0.7007 G_loss:0.7516 R:0.47 F:0.46\n",
      "[002/2] [032/086] D_loss:0.6708 G_loss:0.7616 R:0.51 F:0.47\n",
      "[002/2] [033/086] D_loss:0.6500 G_loss:0.7678 R:0.53 F:0.46\n",
      "[002/2] [034/086] D_loss:0.6274 G_loss:0.7485 R:0.56 F:0.46\n",
      "[002/2] [035/086] D_loss:0.6622 G_loss:0.6880 R:0.53 F:0.47\n",
      "[002/2] [036/086] D_loss:0.6891 G_loss:0.6519 R:0.53 F:0.51\n",
      "[002/2] [037/086] D_loss:0.6876 G_loss:0.7001 R:0.57 F:0.54\n",
      "[002/2] [038/086] D_loss:0.6730 G_loss:0.7635 R:0.55 F:0.51\n",
      "[002/2] [039/086] D_loss:0.6590 G_loss:0.7762 R:0.52 F:0.47\n",
      "[002/2] [040/086] D_loss:0.6891 G_loss:0.6137 R:0.47 F:0.46\n",
      "[002/2] [041/086] D_loss:0.6975 G_loss:0.7860 R:0.58 F:0.57\n",
      "[002/2] [042/086] D_loss:0.6734 G_loss:0.7613 R:0.49 F:0.46\n",
      "[002/2] [043/086] D_loss:0.6970 G_loss:0.7300 R:0.48 F:0.46\n",
      "[002/2] [044/086] D_loss:0.6841 G_loss:0.6659 R:0.50 F:0.48\n",
      "[002/2] [045/086] D_loss:0.6873 G_loss:0.7426 R:0.53 F:0.52\n",
      "[002/2] [046/086] D_loss:0.6766 G_loss:0.8185 R:0.50 F:0.47\n",
      "[002/2] [047/086] D_loss:0.6402 G_loss:0.7931 R:0.51 F:0.44\n",
      "[002/2] [048/086] D_loss:0.7134 G_loss:0.6845 R:0.43 F:0.45\n",
      "[002/2] [049/086] D_loss:0.6874 G_loss:0.7437 R:0.52 F:0.51\n",
      "[002/2] [050/086] D_loss:0.6553 G_loss:0.6735 R:0.53 F:0.47\n",
      "[002/2] [051/086] D_loss:0.6631 G_loss:0.7443 R:0.56 F:0.51\n",
      "[002/2] [052/086] D_loss:0.6413 G_loss:0.7531 R:0.57 F:0.49\n",
      "[002/2] [053/086] D_loss:0.7064 G_loss:0.7920 R:0.47 F:0.47\n",
      "[002/2] [054/086] D_loss:0.6907 G_loss:0.7897 R:0.48 F:0.46\n",
      "[002/2] [055/086] D_loss:0.6787 G_loss:0.7438 R:0.50 F:0.46\n",
      "[002/2] [056/086] D_loss:0.6933 G_loss:0.7252 R:0.48 F:0.48\n",
      "[002/2] [057/086] D_loss:0.6705 G_loss:0.6743 R:0.52 F:0.49\n",
      "[002/2] [058/086] D_loss:0.6850 G_loss:0.7208 R:0.54 F:0.52\n",
      "[002/2] [059/086] D_loss:0.7356 G_loss:0.8671 R:0.45 F:0.49\n",
      "[002/2] [060/086] D_loss:0.7264 G_loss:0.8296 R:0.39 F:0.41\n",
      "[002/2] [061/086] D_loss:0.7164 G_loss:0.7420 R:0.42 F:0.43\n",
      "[002/2] [062/086] D_loss:0.6938 G_loss:0.6843 R:0.48 F:0.48\n",
      "[002/2] [063/086] D_loss:0.6805 G_loss:0.6482 R:0.53 F:0.51\n",
      "[002/2] [064/086] D_loss:0.6877 G_loss:0.6949 R:0.54 F:0.53\n",
      "[002/2] [065/086] D_loss:0.7048 G_loss:0.6967 R:0.49 F:0.51\n",
      "[002/2] [066/086] D_loss:0.7059 G_loss:0.7213 R:0.49 F:0.50\n",
      "[002/2] [067/086] D_loss:0.6619 G_loss:0.7106 R:0.53 F:0.48\n",
      "[002/2] [068/086] D_loss:0.6803 G_loss:0.7141 R:0.51 F:0.49\n",
      "[002/2] [069/086] D_loss:0.6556 G_loss:0.7190 R:0.55 F:0.49\n",
      "[002/2] [070/086] D_loss:0.6777 G_loss:0.7109 R:0.51 F:0.49\n",
      "[002/2] [071/086] D_loss:0.6930 G_loss:0.6872 R:0.50 F:0.49\n",
      "[002/2] [072/086] D_loss:0.7206 G_loss:0.6684 R:0.48 F:0.51\n",
      "[002/2] [073/086] D_loss:0.7010 G_loss:0.6516 R:0.52 F:0.52\n",
      "[002/2] [074/086] D_loss:0.7074 G_loss:0.6969 R:0.53 F:0.54\n",
      "[002/2] [075/086] D_loss:0.6988 G_loss:0.7170 R:0.50 F:0.50\n",
      "[002/2] [076/086] D_loss:0.6955 G_loss:0.7228 R:0.49 F:0.49\n",
      "[002/2] [077/086] D_loss:0.6693 G_loss:0.6992 R:0.52 F:0.48\n",
      "[002/2] [078/086] D_loss:0.6882 G_loss:0.6802 R:0.51 F:0.50\n",
      "[002/2] [079/086] D_loss:0.6807 G_loss:0.6978 R:0.53 F:0.51\n",
      "[002/2] [080/086] D_loss:0.6766 G_loss:0.6847 R:0.52 F:0.50\n",
      "[002/2] [081/086] D_loss:0.6938 G_loss:0.7165 R:0.52 F:0.51\n",
      "[002/2] [082/086] D_loss:0.7038 G_loss:0.7267 R:0.48 F:0.49\n",
      "[002/2] [083/086] D_loss:0.7099 G_loss:0.7277 R:0.47 F:0.48\n",
      "[002/2] [084/086] D_loss:0.6907 G_loss:0.7199 R:0.49 F:0.48\n",
      "[002/2] [085/086] D_loss:0.7034 G_loss:0.7293 R:0.47 F:0.48\n",
      "[002/2] [086/086] D_loss:0.7108 G_loss:0.7397 R:0.46 F:0.48\n",
      "Done. Все результаты — в папке gan_textures/\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    ep_g, ep_d = 0.0, 0.0\n",
    "    ep_r, ep_f = 0.0, 0.0\n",
    "    nb = len(dataloader)\n",
    "\n",
    "    for i, real in enumerate(dataloader, 1):\n",
    "        real = real.to(device)\n",
    "        b = real.size(0)\n",
    "\n",
    "        valid = torch.full((b,1), 0.9, device=device)\n",
    "        fake_lbl = torch.full((b,1), 0.1, device=device)\n",
    "\n",
    "        opt_D.zero_grad()\n",
    "        out_r = D(real)\n",
    "        loss_r = criterion(out_r, valid)\n",
    "\n",
    "        z = torch.randn(b, latent_dim, device=device)\n",
    "        fake = G(z).detach()\n",
    "        out_f = D(fake)\n",
    "        loss_f = criterion(out_f, fake_lbl)\n",
    "\n",
    "        d_loss = 0.5*(loss_r + loss_f)\n",
    "        d_loss.backward()\n",
    "        opt_D.step()\n",
    "\n",
    "        for _ in range(2):\n",
    "            opt_G.zero_grad()\n",
    "            z2 = torch.randn(b, latent_dim, device=device)\n",
    "            gen = G(z2)\n",
    "            out_gen = D(gen)\n",
    "            g_loss = criterion(out_gen, valid)\n",
    "            g_loss.backward()\n",
    "            opt_G.step()\n",
    "\n",
    "        ep_d += d_loss.item()\n",
    "        ep_g += g_loss.item()\n",
    "        ep_r += out_r.mean().item()\n",
    "        ep_f += out_f.mean().item()\n",
    "\n",
    "        print(f\"[{epoch:03d}/{epochs}]\"\n",
    "              f\" [{i:03d}/{nb:03d}]\"\n",
    "              f\" D_loss:{d_loss:.4f}\"\n",
    "              f\" G_loss:{g_loss:.4f}\"\n",
    "              f\" R:{out_r.mean().item():.2f}\"\n",
    "              f\" F:{out_f.mean().item():.2f}\")\n",
    "\n",
    "    d_losses.append(ep_d/nb)\n",
    "    g_losses.append(ep_g/nb)\n",
    "    real_probs.append(ep_r/nb)\n",
    "    fake_probs.append(ep_f/nb)\n",
    "\n",
    "    save_dir = os.path.join('gan_textures', f'epoch{epoch}')\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    with torch.no_grad():\n",
    "        samp_z = torch.randn(32, latent_dim, device=device)\n",
    "        samples = G(samp_z).cpu()\n",
    "        for idx, img in enumerate(samples,1):\n",
    "            torchvision.utils.save_image(img,\n",
    "                os.path.join(save_dir, f\"{idx:02d}.png\"),\n",
    "                normalize=True, value_range=(-1,1)\n",
    "            )\n",
    "\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(g_losses,'-o',label='G Loss')\n",
    "    plt.plot(d_losses,'-o',label='D Loss')\n",
    "    plt.title('Loss per Epoch')\n",
    "    plt.xlabel('Epoch'); plt.legend(); plt.grid(True)\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(real_probs,'-o',label='D(real)')\n",
    "    plt.plot(fake_probs,'-o',label='D(fake)')\n",
    "    plt.title('D Outputs')\n",
    "    plt.xlabel('Epoch'); plt.legend(); plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join('gan_textures','metrics.png'))\n",
    "    plt.close()\n",
    "\n",
    "print(\"Done. Все результаты — в папке gan_textures/\")  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
