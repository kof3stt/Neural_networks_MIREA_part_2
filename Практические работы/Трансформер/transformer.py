import torch
import evaluate
from datasets import load_dataset
from transformers import AutoTokenizer
from transformers import AutoModelForQuestionAnswering
from transformers import TrainingArguments
from transformers import Trainer
from transformers import pipeline
from transformers import default_data_collator
from datasets import load_dataset


MODEL_NAME = "DeepPavlov/rubert-base-cased"


class QADatasetProcessor:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏, —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∑–∞–¥–∞—á–∏ –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç (QA).
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç SQuAD-–ø–æ–¥–æ–±–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç SberQuad.
    """

    def __init__(self, model_name: str = MODEL_NAME):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–¥–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏.

        –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
            model_name (str): –Ω–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏, —Å–æ–≤–º–µ—Å—Ç–∏–º–æ–π —Å Hugging Face.
        """
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)

    def load_data(self):
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç SberQuad –∏–∑ Hugging Face Datasets.

        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
            DatasetDict: —Å–ª–æ–≤–∞—Ä—å —Å —Ä–∞–∑–±–∏–≤–∫–æ–π –Ω–∞ train –∏ validation.
        """
        self.dataset = load_dataset("kuznetsoffandrey/sberquad")
        return self.dataset

    def _preprocess_examples(self, examples):
        """
        –¢–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ—Ç –∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –ø—Ä–∏–º–µ—Ä—ã –≤ —Ñ–æ—Ä–º–∞—Ç, —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π —Å –º–æ–¥–µ–ª—å—é –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç.

        –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
            examples (dict): –±–∞—Ç—á –ø—Ä–∏–º–µ—Ä–æ–≤ –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞.

        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
            dict: —Å–ª–æ–≤–∞—Ä—å —Å —Ç–æ–∫–µ–Ω–∞–º–∏ –∏ –ø–æ–∑–∏—Ü–∏—è–º–∏ –Ω–∞—á–∞–ª–∞ –∏ –∫–æ–Ω—Ü–∞ –æ—Ç–≤–µ—Ç–æ–≤.
        """
        questions = examples["question"]
        contexts = examples["context"]
        answers = examples["answers"]

        answer_starts = [ans["answer_start"][0] for ans in answers]
        answer_texts = [ans["text"][0] for ans in answers]

        inputs = self.tokenizer(
            questions,
            contexts,
            max_length=384,
            truncation="only_second",
            stride=128,
            return_overflowing_tokens=True,
            return_offsets_mapping=True,
            padding="max_length",
        )

        offset_mapping = inputs.pop("offset_mapping")
        overflow_to_sample_mapping = inputs.pop("overflow_to_sample_mapping")

        start_positions = []
        end_positions = []

        for i, offsets in enumerate(offset_mapping):
            sample_idx = overflow_to_sample_mapping[i]
            start_char = answer_starts[sample_idx]
            end_char = start_char + len(answer_texts[sample_idx])

            sequence_ids = inputs.sequence_ids(i)
            context_start = sequence_ids.index(1)
            context_end = len(sequence_ids) - 1 - sequence_ids[::-1].index(1)

            if not (
                offsets[context_start][0]
                <= start_char
                < end_char
                <= offsets[context_end][1]
            ):
                start_positions.append(0)
                end_positions.append(0)
                continue

            token_start = context_start
            while token_start <= context_end and offsets[token_start][0] <= start_char:
                token_start += 1
            start_positions.append(token_start - 1)

            token_end = context_end
            while token_end >= context_start and offsets[token_end][1] >= end_char:
                token_end -= 1
            end_positions.append(token_end + 1)

        inputs["start_positions"] = start_positions
        inputs["end_positions"] = end_positions
        inputs["overflow_to_sample_mapping"] = overflow_to_sample_mapping
        return inputs

    def get_tokenized_dataset(self, dataset):
        """
        –ü—Ä–∏–º–µ–Ω—è–µ—Ç —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—é –∫–æ –≤—Å–µ–º—É –¥–∞—Ç–∞—Å–µ—Ç—É.

        –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
            dataset (DatasetDict): –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç SberQuad.

        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
            DatasetDict: —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç.
        """
        return dataset.map(
            self._preprocess_examples,
            batched=True,
            remove_columns=dataset["train"].column_names,
            batch_size=100,
        )


class QAModelTrainer:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –Ω–∞ –∑–∞–¥–∞—á–µ –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Trainer API.
    """

    def __init__(
        self, model_name: str = MODEL_NAME, tokenizer=None, training_args: dict = None
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –∏ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏.

        –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
            model_name (str): –∏–º—è –º–æ–¥–µ–ª–∏.
            tokenizer: —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä, –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–π –≤ pipeline.
            training_args (dict): —Å–ª–æ–≤–∞—Ä—å —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –æ–±—É—á–µ–Ω–∏—è.
        """
        self.model = AutoModelForQuestionAnswering.from_pretrained(model_name)
        self.tokenizer = tokenizer
        self.training_args = training_args or {
            "output_dir": "./results",
            "learning_rate": 2e-5,
            "per_device_train_batch_size": 8,
            "num_train_epochs": 3,
            "weight_decay": 0.01,
            "eval_strategy": "epoch",
            "save_strategy": "epoch",
            "logging_dir": "./logs",
            "fp16": torch.cuda.is_available(),
        }

    def setup_trainer(self, tokenized_dataset, original_dataset):
        """
        –°–æ–∑–¥–∞—ë—Ç Trainer —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏, –º–æ–¥–µ–ª—å—é –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏.

        –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
            tokenized_dataset (DatasetDict): —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç.
            original_dataset (DatasetDict): –∏—Å—Ö–æ–¥–Ω—ã–π SberQuad.

        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
            Trainer: –æ–±—ä–µ–∫—Ç Trainer.
        """
        args = TrainingArguments(**self.training_args)
        squad_metric = evaluate.load("squad_v2")

        def compute_metrics(p):
            """–í—ã—á–∏—Å–ª—è–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ —Ç–æ—á–Ω–æ—Å—Ç–∏ –¥–ª—è –∑–∞–¥–∞—á–∏ QA."""
            start_logits, end_logits = p.predictions
            start_pred = torch.argmax(torch.tensor(start_logits), dim=1).numpy()
            end_pred = torch.argmax(torch.tensor(end_logits), dim=1).numpy()

            formatted_predictions = []
            references = []

            for i in range(len(start_pred)):
                sample_idx = tokenized_dataset["validation"][i][
                    "overflow_to_sample_mapping"
                ]
                original_sample = original_dataset["validation"][sample_idx]

                prediction_text = self.tokenizer.decode(
                    tokenized_dataset["validation"][i]["input_ids"][
                        start_pred[i] : end_pred[i] + 1
                    ],
                    skip_special_tokens=True,
                )

                references.append(
                    {
                        "id": str(original_sample["id"]),
                        "answers": {
                            "text": original_sample["answers"]["text"],
                            "answer_start": original_sample["answers"]["answer_start"],
                        },
                    }
                )

                formatted_predictions.append(
                    {
                        "id": str(original_sample["id"]),
                        "prediction_text": prediction_text,
                        "no_answer_probability": 0.0,
                    }
                )

            return squad_metric.compute(
                predictions=formatted_predictions, references=references
            )

        self.trainer = Trainer(
            model=self.model,
            args=args,
            train_dataset=tokenized_dataset["train"],
            eval_dataset=tokenized_dataset["validation"],
            data_collator=default_data_collator,
            compute_metrics=compute_metrics,
        )
        return self.trainer

    def train(self):
        """–ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏."""
        return self.trainer.train()

    def save_model(self, path: str = "./sberquad_qa_model"):
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –º–æ–¥–µ–ª—å –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –≤ —É–∫–∞–∑–∞–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é.

        –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
            path (str): –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è.
        """
        self.model.save_pretrained(path)
        self.tokenizer.save_pretrained(path)


class QAPipeline:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π —Å –ø–æ–º–æ—â—å—é –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ question-answering pipeline.
    """

    def __init__(self, model_path: str = "./sberquad_qa_model"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª—å –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –∏–∑ —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –ø—É—Ç–∏.

        –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
            model_path (str): –ø—É—Ç—å –¥–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –º–æ–¥–µ–ª—å—é.
        """
        self.model = AutoModelForQuestionAnswering.from_pretrained(model_path)
        self.tokenizer = AutoTokenizer.from_pretrained(model_path)
        self.pipeline = pipeline(
            "question-answering",
            model = self.model,
            tokenizer = self.tokenizer,
            device = 0 if torch.cuda.is_available() else -1,
        )

    def predict(self, context: str, question: str):
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ –∑–∞–¥–∞–Ω–Ω–æ–º—É –∫–æ–Ω—Ç–µ–∫—Å—Ç—É.

        –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
            context (str): —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç.
            question (str): –≤–æ–ø—Ä–æ—Å –∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É.

        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
            dict: —Å–ª–æ–≤–∞—Ä—å —Å –æ—Ç–≤–µ—Ç–æ–º –∏ –æ—Ü–µ–Ω–∫–æ–π.
        """
        return self.pipeline(
            question=question,
            context=context,
            max_seq_len=384,
            doc_stride=128,
            handle_impossible_answer=True,
        )


if __name__ == "__main__":
    processor = QADatasetProcessor()
    dataset = processor.load_data()
    tokenized_dataset = processor.get_tokenized_dataset(dataset)

    trainer = QAModelTrainer(tokenizer=processor.tokenizer)
    trainer.setup_trainer(tokenized_dataset, dataset)
    trainer.train()
    trainer.save_model()

    qa_system = QAPipeline()
    context = (
        "–ü–µ—Ä–≤—ã–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –æ —Å—Ç—Ä–æ–µ–Ω–∏–∏ —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–≥–æ —Ç–µ–ª–∞ –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è –≤ –î—Ä–µ–≤–Ω–µ–º –ï–≥–∏–ø—Ç–µ."
    )
    question = "–ì–¥–µ –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è –ø–µ—Ä–≤—ã–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –æ —Å—Ç—Ä–æ–µ–Ω–∏–∏ —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–≥–æ —Ç–µ–ª–∞?"

    result = qa_system.predict(context, question)
    print(f"–†–µ–∑—É–ª—å—Ç–∏—Ä—É—é—â–∏–π —Å–ª–æ–≤–∞—Ä—å: {result}")
    print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è:")
    print(f"–í–æ–ø—Ä–æ—Å: {question}")
    print(f"–û—Ç–≤–µ—Ç: {result['answer']}")
    print(f"–¢–æ—á–Ω–æ—Å—Ç—å: {result['score']:.2f}")

    print("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ:")
    test_data = dataset["test"]

    for i, sample in enumerate(test_data.select(range(10))):
        context = sample["context"]
        question = sample["question"]
        true_answer = sample["answers"]["text"][0]

        prediction = qa_system.predict(context, question)

        print(f"–ü—Ä–∏–º–µ—Ä {i + 1}")
        print(f"–í–æ–ø—Ä–æ—Å: {question}")
        print(f"–ö–æ–Ω—Ç–µ–∫—Å—Ç: {context}")
        print(f"–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç: {true_answer}")
        print(f"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {prediction['answer']}")
        print(f"–¢–æ—á–Ω–æ—Å—Ç—å: {prediction['score']:.2f}")

    print("\nüìä –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ –≤—Å–µ–π —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ...")

    squad_metric = evaluate.load("squad_v2")

    test_data = dataset["test"]

    predictions = []
    references = []

    for sample in test_data:
        context = sample["context"]
        question = sample["question"]
        true_answers = sample["answers"]["text"]
        
        result = qa_system.predict(context, question)
        
        predictions.append({
            "id": str(sample["id"]),
            "prediction_text": result["answer"],
            "no_answer_probability": 0.0
        })
        
        references.append({
            "id": str(sample["id"]),
            "answers": {
                "text": true_answers,
                "answer_start": sample["answers"]["answer_start"]
            }
        })

    metrics = squad_metric.compute(predictions=predictions, references=references)

    print("üìà –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ:")
    print(f"üìå Exact Match (EM): {metrics['exact']:.2f}")
    print(f"üìå F1 Score: {metrics['f1']:.2f}")
